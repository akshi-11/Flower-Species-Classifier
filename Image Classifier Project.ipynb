{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image Classifier Project.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Nvefy8ZT_hW5","colab_type":"text"},"cell_type":"markdown","source":["# Developing an AI application\n","\n","Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n","\n","In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n","\n","<img src='assets/Flowers.png' width=500px>\n","\n","The project is broken down into multiple steps:\n","\n","* Load and preprocess the image dataset\n","* Train the image classifier on your dataset\n","* Use the trained classifier to predict image content\n","\n","We'll lead you through each part which you'll implement in Python.\n","\n","When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n","\n","First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."]},{"metadata":{"id":"oAZGaTwn_rBH","colab_type":"code","colab":{}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b_AU7XR-V7Za","colab_type":"code","outputId":"4cca8b74-eb60-4135-cf09-7aa9ed27f137","executionInfo":{"status":"ok","timestamp":1547268452223,"user_tz":-330,"elapsed":4636,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Imports here\n","from torch import nn, optim\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","!pip install -U pillow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: pillow in /usr/local/lib/python3.6/dist-packages (5.4.1)\n"],"name":"stdout"}]},{"metadata":{"id":"Cw64Ru-1_hXD","colab_type":"text"},"cell_type":"markdown","source":["## Load the data\n","\n","Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). You can [download the data here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip). The dataset is split into two parts, training and validation. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. If you use a pre-trained network, you'll also need to make sure the input data is resized to 224x224 pixels as required by the networks.\n","\n","The validation set is used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n","\n","The pre-trained networks available from `torchvision` were trained on the ImageNet dataset where each color channel was normalized separately. For both sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1."]},{"metadata":{"id":"_giOu-U-_hXE","colab_type":"code","outputId":"2bd5589f-b6d3-40cb-84cd-840190644f21","executionInfo":{"status":"ok","timestamp":1547268512768,"user_tz":-330,"elapsed":56381,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir = '/content/drive/My Drive/Colab Notebooks/pytorch_challenge/flower_data'\n","train_dir = data_dir + '/train'\n","valid_dir = data_dir + '/valid'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"QVTr-BtV_hXK","colab_type":"code","colab":{}},"cell_type":"code","source":["# TODO: Define your transforms for the training and validation sets\n","\n","batch_size = 32\n","\n","train_transforms = transforms.Compose([transforms.RandomRotation(30),\n","                                       transforms.RandomHorizontalFlip(),\n","                                       transforms.RandomResizedCrop(224),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","valid_transforms = transforms.Compose([transforms.Resize(255),\n","                                       transforms.CenterCrop(224),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize([0.485, 0.456, 0.406],\n","                                                            [0.229, 0.224, 0.225])])\n","\n","# TODO: Load the datasets with ImageFolder\n","train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n","valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n","\n","# TODO: Using the image datasets and the trainforms, define the dataloaders\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","validloader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xELTXJRcR43_","colab_type":"code","outputId":"aecedf41-971c-4ed7-8a50-a043c0192032","executionInfo":{"status":"ok","timestamp":1547268655969,"user_tz":-330,"elapsed":11509,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","images = images.numpy()\n","print(images.shape)\n","print(labels.shape)\n","print(images[0].size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(32, 3, 224, 224)\n","torch.Size([32])\n","150528\n"],"name":"stdout"}]},{"metadata":{"id":"IhxusTJ0i0j3","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# helper function to un-normalize and display an image\n","def imshow(img):\n","  image = torch.from_numpy(img)\n","  image = image.clone()\n","  image = image.numpy().squeeze()\n","  image = image.transpose(1,2,0)\n","  image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n","  image = image.clip(0, 1)\n","  \n","  return image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KToAxHHS_hXP","colab_type":"text"},"cell_type":"markdown","source":["### Label mapping\n","\n","You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."]},{"metadata":{"id":"oejPGebK_hXR","colab_type":"code","colab":{}},"cell_type":"code","source":["import json\n","\n","with open('/content/drive/My Drive/Colab Notebooks/pytorch_challenge/cat_to_name.json', 'r') as f:\n","    cat_to_name = json.load(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iMJJs0wfk4dK","colab_type":"code","outputId":"86d9f46e-2896-4d29-94c2-2d24996bfc39","executionInfo":{"status":"ok","timestamp":1547270541465,"user_tz":-330,"elapsed":911,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["cat_to_name = {int(k):v for k,v in cat_to_name.items()}\n","names = []\n","for key in sorted(cat_to_name.keys()):\n","  names.append(cat_to_name[key])\n","print(names)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'english marigold', 'tiger lily', 'moon orchid', 'bird of paradise', 'monkshood', 'globe thistle', 'snapdragon', \"colt's foot\", 'king protea', 'spear thistle', 'yellow iris', 'globe-flower', 'purple coneflower', 'peruvian lily', 'balloon flower', 'giant white arum lily', 'fire lily', 'pincushion flower', 'fritillary', 'red ginger', 'grape hyacinth', 'corn poppy', 'prince of wales feathers', 'stemless gentian', 'artichoke', 'sweet william', 'carnation', 'garden phlox', 'love in the mist', 'mexican aster', 'alpine sea holly', 'ruby-lipped cattleya', 'cape flower', 'great masterwort', 'siam tulip', 'lenten rose', 'barbeton daisy', 'daffodil', 'sword lily', 'poinsettia', 'bolero deep blue', 'wallflower', 'marigold', 'buttercup', 'oxeye daisy', 'common dandelion', 'petunia', 'wild pansy', 'primula', 'sunflower', 'pelargonium', 'bishop of llandaff', 'gaura', 'geranium', 'orange dahlia', 'pink-yellow dahlia', 'cautleya spicata', 'japanese anemone', 'black-eyed susan', 'silverbush', 'californian poppy', 'osteospermum', 'spring crocus', 'bearded iris', 'windflower', 'tree poppy', 'gazania', 'azalea', 'water lily', 'rose', 'thorn apple', 'morning glory', 'passion flower', 'lotus lotus', 'toad lily', 'anthurium', 'frangipani', 'clematis', 'hibiscus', 'columbine', 'desert-rose', 'tree mallow', 'magnolia', 'cyclamen', 'watercress', 'canna lily', 'hippeastrum', 'bee balm', 'ball moss', 'foxglove', 'bougainvillea', 'camellia', 'mallow', 'mexican petunia', 'bromelia', 'blanket flower', 'trumpet creeper', 'blackberry lily']\n"],"name":"stdout"}]},{"metadata":{"id":"c4kYDyO9hlo-","colab_type":"code","outputId":"46b73f69-2a9f-413e-e7fc-448d6dc96e1e","executionInfo":{"status":"ok","timestamp":1547272569286,"user_tz":-330,"elapsed":11199,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"cell_type":"code","source":["dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","# print(labels[0])\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(25, 4))\n","# display 20 images\n","for idx in np.arange(32):\n","#   print(idx)\n","  ax = fig.add_subplot(2, 32/2, idx+1, xticks=[], yticks=[])\n","  imshow(images[idx])\n","#   print(labels[idx])\n","  ax.set_title(names[labels[idx]-1])"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABYgAAAD2CAYAAAB8xWOhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7fcea3ff4390>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"JlNsPxfT_hXW","colab_type":"text"},"cell_type":"markdown","source":["# Building and training the classifier\n","\n","Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n","\n","We're going to leave this part up to you. If you want to talk through it with someone, chat with your fellow students! You can also ask questions on the forums or join the instructors in office hours.\n","\n","Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n","\n","* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n","* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n","* Train the classifier layers using backpropagation using the pre-trained network to get the features\n","* Track the loss and accuracy on the validation set to determine the best hyperparameters\n","\n","We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n","\n","When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project."]},{"metadata":{"id":"fpD-EgqW_hXY","colab_type":"code","outputId":"1b5beb94-6927-4c22-a02b-2bf19b255663","executionInfo":{"status":"ok","timestamp":1546964229739,"user_tz":-330,"elapsed":1695,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["model = models.densenet201(pretrained=True)\n","\n","for param in model.parameters():\n","  param.requires_grad = False\n","\n","model.classifier = nn.Sequential(nn.Linear(1920, 102),\n","                         nn.LogSoftmax(dim=1))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(m.weight.data)\n"],"name":"stderr"}]},{"metadata":{"id":"F_GZ8ldxeKJq","colab_type":"code","outputId":"bc32fb4e-ae35-48f1-f982-0db957c72480","executionInfo":{"status":"ok","timestamp":1546964236857,"user_tz":-330,"elapsed":1207,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":14008}},"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model.to(device)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DenseNet(\n","  (features): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace)\n","    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (denseblock1): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition1): _Transition(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock2): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition2): _Transition(\n","      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock3): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer25): _DenseLayer(\n","        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer26): _DenseLayer(\n","        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer27): _DenseLayer(\n","        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer28): _DenseLayer(\n","        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer29): _DenseLayer(\n","        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer30): _DenseLayer(\n","        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer31): _DenseLayer(\n","        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer32): _DenseLayer(\n","        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer33): _DenseLayer(\n","        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer34): _DenseLayer(\n","        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer35): _DenseLayer(\n","        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer36): _DenseLayer(\n","        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer37): _DenseLayer(\n","        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer38): _DenseLayer(\n","        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer39): _DenseLayer(\n","        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer40): _DenseLayer(\n","        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer41): _DenseLayer(\n","        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer42): _DenseLayer(\n","        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer43): _DenseLayer(\n","        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer44): _DenseLayer(\n","        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer45): _DenseLayer(\n","        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer46): _DenseLayer(\n","        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer47): _DenseLayer(\n","        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer48): _DenseLayer(\n","        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition3): _Transition(\n","      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock4): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer25): _DenseLayer(\n","        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer26): _DenseLayer(\n","        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer27): _DenseLayer(\n","        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer28): _DenseLayer(\n","        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer29): _DenseLayer(\n","        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer30): _DenseLayer(\n","        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer31): _DenseLayer(\n","        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer32): _DenseLayer(\n","        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=1920, out_features=102, bias=True)\n","    (1): LogSoftmax()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"znZ0DHTkNFuY","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qVRw-ROxNxpv","colab_type":"code","outputId":"f8ccd4e8-7515-4576-abdf-40d3e4830ca0","executionInfo":{"status":"error","timestamp":1546972120906,"user_tz":-330,"elapsed":1413835,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":1880}},"cell_type":"code","source":["\n","n_epochs = 60\n","valid_loss_min = np.inf\n","\n","for epoch in range(1, n_epochs+1):\n","\n","  train_loss = 0\n","  valid_loss = 0\n","  accuracy = 0\n","\n","  ###############\n","  #### train ####\n","  ###############\n","\n","\n","  model.train()\n","\n","  for idx, (data, label) in enumerate(trainloader):\n","    if torch.cuda.is_available():\n","      data, label = data.to('cuda'), label.to('cuda')\n","#     print(data.size(0))\n","    optimizer.zero_grad()\n","    output = model(data)\n","    loss = criterion(output, label)\n","    loss.backward()\n","    optimizer.step()\n","    train_loss += loss.item()*data.size(0)\n","\n","  ###############\n","  ## validate ###\n","  ###############\n","\n","  model.eval()\n","  for idx, (data, label) in enumerate(validloader):\n","    if torch.cuda.is_available():\n","      data, label = data.to('cuda'), label.to('cuda')\n","\n","    output = model(data)\n","    loss = criterion(output, label)\n","    valid_loss += loss.item()*data.size(0)\n","    ps = torch.exp(output)\n","    top_p, top_class = ps.topk(1, dim=1)\n","    equals = top_class == label.view(*top_class.shape)\n","    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","  train_loss = train_loss/len(trainloader.dataset)\n","  valid_loss = valid_loss/len(validloader.dataset)\n","  scheduler.step(valid_loss)\n","\n","  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAccuracy: {:.6f}'.format(\n","        epoch, train_loss, valid_loss, accuracy/len(validloader)))\n","\n","  # save model if validation loss has decreased\n","  if valid_loss <= valid_loss_min:\n","      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","      valid_loss_min,\n","      valid_loss))\n","      torch.save(model.state_dict(), F\"/content/drive/My Drive/classifierplat.pt\")\n","      valid_loss_min = valid_loss\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 2.542682 \tValidation Loss: 1.009287 \tAccuracy: 0.863248\n","Validation loss decreased (inf --> 1.009287).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.957273 \tValidation Loss: 0.468378 \tAccuracy: 0.934428\n","Validation loss decreased (1.009287 --> 0.468378).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.644223 \tValidation Loss: 0.356207 \tAccuracy: 0.944979\n","Validation loss decreased (0.468378 --> 0.356207).  Saving model ...\n","Epoch: 4 \tTraining Loss: 0.498802 \tValidation Loss: 0.282679 \tAccuracy: 0.948584\n","Validation loss decreased (0.356207 --> 0.282679).  Saving model ...\n","Epoch: 5 \tTraining Loss: 0.427597 \tValidation Loss: 0.247690 \tAccuracy: 0.944712\n","Validation loss decreased (0.282679 --> 0.247690).  Saving model ...\n","Epoch: 6 \tTraining Loss: 0.379721 \tValidation Loss: 0.209905 \tAccuracy: 0.955529\n","Validation loss decreased (0.247690 --> 0.209905).  Saving model ...\n","Epoch: 7 \tTraining Loss: 0.358256 \tValidation Loss: 0.195956 \tAccuracy: 0.956731\n","Validation loss decreased (0.209905 --> 0.195956).  Saving model ...\n","Epoch: 8 \tTraining Loss: 0.309236 \tValidation Loss: 0.178788 \tAccuracy: 0.954594\n","Validation loss decreased (0.195956 --> 0.178788).  Saving model ...\n","Epoch: 9 \tTraining Loss: 0.306597 \tValidation Loss: 0.178145 \tAccuracy: 0.962740\n","Validation loss decreased (0.178788 --> 0.178145).  Saving model ...\n","Epoch: 10 \tTraining Loss: 0.298182 \tValidation Loss: 0.183258 \tAccuracy: 0.956731\n","Epoch: 11 \tTraining Loss: 0.265056 \tValidation Loss: 0.164377 \tAccuracy: 0.968750\n","Validation loss decreased (0.178145 --> 0.164377).  Saving model ...\n","Epoch: 12 \tTraining Loss: 0.241286 \tValidation Loss: 0.168379 \tAccuracy: 0.957532\n","Epoch: 13 \tTraining Loss: 0.262204 \tValidation Loss: 0.170453 \tAccuracy: 0.960337\n","Epoch: 14 \tTraining Loss: 0.250259 \tValidation Loss: 0.160250 \tAccuracy: 0.964209\n","Validation loss decreased (0.164377 --> 0.160250).  Saving model ...\n","Epoch: 15 \tTraining Loss: 0.233522 \tValidation Loss: 0.167761 \tAccuracy: 0.948584\n","Epoch: 16 \tTraining Loss: 0.219032 \tValidation Loss: 0.148552 \tAccuracy: 0.963942\n","Validation loss decreased (0.160250 --> 0.148552).  Saving model ...\n","Epoch: 17 \tTraining Loss: 0.217165 \tValidation Loss: 0.136234 \tAccuracy: 0.969017\n","Validation loss decreased (0.148552 --> 0.136234).  Saving model ...\n","Epoch: 18 \tTraining Loss: 0.213968 \tValidation Loss: 0.150960 \tAccuracy: 0.962740\n","Epoch: 19 \tTraining Loss: 0.223485 \tValidation Loss: 0.157568 \tAccuracy: 0.960337\n","Epoch: 20 \tTraining Loss: 0.219762 \tValidation Loss: 0.148827 \tAccuracy: 0.962340\n","Epoch: 21 \tTraining Loss: 0.186789 \tValidation Loss: 0.135134 \tAccuracy: 0.967548\n","Validation loss decreased (0.136234 --> 0.135134).  Saving model ...\n","Epoch: 22 \tTraining Loss: 0.217498 \tValidation Loss: 0.140707 \tAccuracy: 0.967815\n","Epoch: 23 \tTraining Loss: 0.203317 \tValidation Loss: 0.145544 \tAccuracy: 0.966880\n","Epoch: 24 \tTraining Loss: 0.207467 \tValidation Loss: 0.132437 \tAccuracy: 0.971421\n","Validation loss decreased (0.135134 --> 0.132437).  Saving model ...\n","Epoch: 25 \tTraining Loss: 0.200609 \tValidation Loss: 0.147694 \tAccuracy: 0.961538\n","Epoch: 26 \tTraining Loss: 0.185133 \tValidation Loss: 0.136808 \tAccuracy: 0.966346\n","Epoch: 27 \tTraining Loss: 0.185023 \tValidation Loss: 0.138752 \tAccuracy: 0.965144\n","Epoch: 28 \tTraining Loss: 0.180951 \tValidation Loss: 0.132057 \tAccuracy: 0.970486\n","Validation loss decreased (0.132437 --> 0.132057).  Saving model ...\n","Epoch: 29 \tTraining Loss: 0.178390 \tValidation Loss: 0.152029 \tAccuracy: 0.965411\n","Epoch: 30 \tTraining Loss: 0.193051 \tValidation Loss: 0.136720 \tAccuracy: 0.972356\n","Epoch: 31 \tTraining Loss: 0.190446 \tValidation Loss: 0.137672 \tAccuracy: 0.972356\n","Epoch: 32 \tTraining Loss: 0.181549 \tValidation Loss: 0.134023 \tAccuracy: 0.962073\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-fd7b6ecd95ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \"\"\"\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"n1xqlmB4mBOI","colab_type":"code","outputId":"885a73d9-8eca-4829-aa80-ba0e751b04d9","executionInfo":{"status":"ok","timestamp":1546887093600,"user_tz":-330,"elapsed":2209,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":14062}},"cell_type":"code","source":["def load_checkpoint(checkpoint_path):\n","    model = models.densenet201(pretrained=True)\n","    model.classifier = nn.Sequential(nn.Linear(1920, 102),\n","                                     nn.LogSoftmax(dim=1))\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint, strict=False)\n","    for param in model.parameters():\n","        param.requires_grad = True\n","    model.eval()\n","    return model\n","                               \n","                               \n","# Load your model to this variable\n","model = load_checkpoint(F'/content/drive/My Drive/classifierplat.pt')\n","model.to(device)\n","                               \n","                          "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n","  nn.init.kaiming_normal(m.weight.data)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["DenseNet(\n","  (features): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu0): ReLU(inplace)\n","    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (denseblock1): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition1): _Transition(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock2): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition2): _Transition(\n","      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock3): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer25): _DenseLayer(\n","        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer26): _DenseLayer(\n","        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer27): _DenseLayer(\n","        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer28): _DenseLayer(\n","        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer29): _DenseLayer(\n","        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer30): _DenseLayer(\n","        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer31): _DenseLayer(\n","        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer32): _DenseLayer(\n","        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer33): _DenseLayer(\n","        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer34): _DenseLayer(\n","        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer35): _DenseLayer(\n","        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer36): _DenseLayer(\n","        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer37): _DenseLayer(\n","        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer38): _DenseLayer(\n","        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer39): _DenseLayer(\n","        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer40): _DenseLayer(\n","        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer41): _DenseLayer(\n","        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer42): _DenseLayer(\n","        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer43): _DenseLayer(\n","        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer44): _DenseLayer(\n","        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer45): _DenseLayer(\n","        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer46): _DenseLayer(\n","        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer47): _DenseLayer(\n","        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer48): _DenseLayer(\n","        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (transition3): _Transition(\n","      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace)\n","      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","    )\n","    (denseblock4): _DenseBlock(\n","      (denselayer1): _DenseLayer(\n","        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer2): _DenseLayer(\n","        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer3): _DenseLayer(\n","        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer4): _DenseLayer(\n","        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer5): _DenseLayer(\n","        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer6): _DenseLayer(\n","        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer7): _DenseLayer(\n","        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer8): _DenseLayer(\n","        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer9): _DenseLayer(\n","        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer10): _DenseLayer(\n","        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer11): _DenseLayer(\n","        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer12): _DenseLayer(\n","        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer13): _DenseLayer(\n","        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer14): _DenseLayer(\n","        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer15): _DenseLayer(\n","        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer16): _DenseLayer(\n","        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer17): _DenseLayer(\n","        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer18): _DenseLayer(\n","        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer19): _DenseLayer(\n","        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer20): _DenseLayer(\n","        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer21): _DenseLayer(\n","        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer22): _DenseLayer(\n","        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer23): _DenseLayer(\n","        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer24): _DenseLayer(\n","        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer25): _DenseLayer(\n","        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer26): _DenseLayer(\n","        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer27): _DenseLayer(\n","        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer28): _DenseLayer(\n","        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer29): _DenseLayer(\n","        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer30): _DenseLayer(\n","        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer31): _DenseLayer(\n","        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","      (denselayer32): _DenseLayer(\n","        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu1): ReLU(inplace)\n","        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu2): ReLU(inplace)\n","        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      )\n","    )\n","    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=1920, out_features=102, bias=True)\n","    (1): LogSoftmax()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"9ug-jf0mmufg","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.NLLLoss()\n","optimizer = optim.Adagrad(model.parameters(), lr=0.0001)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,'min')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n37F9a-znFqr","colab_type":"code","outputId":"d2971b91-d402-40eb-ec31-6d30a10952f2","executionInfo":{"status":"error","timestamp":1546887120227,"user_tz":-330,"elapsed":3400,"user":{"displayName":"Akshita Agarwal","photoUrl":"","userId":"07517316342038369100"}},"colab":{"base_uri":"https://localhost:8080/","height":1659}},"cell_type":"code","source":["n_epochs = 60\n","valid_loss_min = np.inf\n","\n","for epoch in range(1, n_epochs+1):\n","  \n","  train_loss = 0\n","  valid_loss = 0\n","  accuracy = 0\n","  \n","  ###############\n","  #### train ####\n","  ###############\n","#   scheduler.step()\n","  \n","  model.train()\n","  \n","  for idx, (data, label) in enumerate(trainloader):\n","    if torch.cuda.is_available():\n","      data, label = data.to('cuda'), label.to('cuda')\n","    \n","    optimizer.zero_grad()\n","    output = model(data)\n","    loss = criterion(output, label)\n","    loss.backward()\n","    optimizer.step()\n","    train_loss += loss.item()*data.size(0)\n","    \n","  ###############\n","  ## validate ###\n","  ###############\n","  \n","  model.eval()\n","  for idx, (data, label) in enumerate(validloader):\n","    if torch.cuda.is_available():\n","      data, label = data.to('cuda'), label.to('cuda')\n","    \n","    output = model(data)\n","    loss = criterion(output, label)\n","    valid_loss += loss.item()*data.size(0)\n","    ps = torch.exp(output)\n","    top_p, top_class = ps.topk(1, dim=1)\n","    equals = top_class == label.view(*top_class.shape)\n","    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","  train_loss = train_loss/len(trainloader.dataset)\n","  valid_loss = valid_loss/len(validloader.dataset)\n","  scheduler.step(valid_loss)\n","  \n","  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAccuracy: {:.6f}'.format(\n","        epoch, train_loss, valid_loss, accuracy/len(validloader)))\n","\n","  # save model if validation loss has decreased\n","  if valid_loss <= valid_loss_min:\n","      print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","      valid_loss_min,\n","      valid_loss))\n","      torch.save(model.state_dict(), F\"/content/drive/My Drive/classifierplatun.pt\")\n","      valid_loss_min = valid_loss\n","  "],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-53a711c649f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DenseLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     )\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"]}]},{"metadata":{"id":"9O51Uwu2_hXd","colab_type":"text"},"cell_type":"markdown","source":["## Save the checkpoint\n","\n","Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n","\n","```model.class_to_idx = image_datasets['train'].class_to_idx```\n","\n","Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."]},{"metadata":{"id":"_6qE3OqW-hk5","colab_type":"code","colab":{}},"cell_type":"code","source":["model.class_to_idx = train_data.class_to_idx\n","model.cpu\n","torch.save({'state_dict':model.state_dict(),\n","            'class_to_idx':model.class_to_idx},\n","            'checkpointplatun.pth')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lX0CFaT5_hXk","colab_type":"text"},"cell_type":"markdown","source":["## Loading the checkpoint\n","\n","At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."]},{"metadata":{"id":"-mmYIpjIRuAz","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_model(checkpoint_path):\n","    model = models.densenet201(pretrained=True)\n","    model.classifier = nn.Sequential(nn.Linear(1920, 102),\n","                                     nn.LogSoftmax(dim=1))\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint, strict=False)\n","    model.class_to_idx = checkpoint['class_to_idx']\n","    model.eval()\n","    \n","    \n","load_model('checkpointplatun.pth')  \n","print(model)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q6PPV4q__hXs","colab_type":"text"},"cell_type":"markdown","source":["# Inference for classification\n","\n","Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n","\n","```python\n","probs, classes = predict(image_path, model)\n","print(probs)\n","print(classes)\n","> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n","> ['70', '3', '45', '62', '55']\n","```\n","\n","First you'll need to handle processing the input image such that it can be used in your network. \n","\n","## Image Preprocessing\n","\n","You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n","\n","First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n","\n","Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n","\n","As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n","\n","And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."]},{"metadata":{"id":"Jtd2aY0i_hXx","colab_type":"code","colab":{}},"cell_type":"code","source":["def process_image(image):\n","    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n","        returns an Numpy array\n","    '''\n","    \n","    # TODO: Process a PIL image for use in a PyTorch model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"51Zf4D8Y_hX3","colab_type":"text"},"cell_type":"markdown","source":["To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."]},{"metadata":{"id":"HVKojqyc_hX4","colab_type":"code","colab":{}},"cell_type":"code","source":["def imshow(image, ax=None, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    if ax is None:\n","        fig, ax = plt.subplots()\n","    \n","    # PyTorch tensors assume the color channel is the first dimension\n","    # but matplotlib assumes is the third dimension\n","    image = image.numpy().transpose((1, 2, 0))\n","    \n","    # Undo preprocessing\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    image = std * image + mean\n","    \n","    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n","    image = np.clip(image, 0, 1)\n","    \n","    ax.imshow(image)\n","    \n","    return ax"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xhEy0RBi_hX8","colab_type":"text"},"cell_type":"markdown","source":["## Class Prediction\n","\n","Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n","\n","To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n","\n","Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n","\n","```python\n","probs, classes = predict(image_path, model)\n","print(probs)\n","print(classes)\n","> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n","> ['70', '3', '45', '62', '55']\n","```"]},{"metadata":{"id":"l0_-M9lq_hX-","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict(image_path, model, topk=5):\n","    ''' Predict the class (or classes) of an image using a trained deep learning model.\n","    '''\n","    \n","    # TODO: Implement the code to predict the class from an image file"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dGNSPvKl_hYD","colab_type":"text"},"cell_type":"markdown","source":["## Sanity Checking\n","\n","Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the validation accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n","\n","<img src='assets/inference_example.png' width=300px>\n","\n","You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."]},{"metadata":{"id":"xOQr8Pv2_hYF","colab_type":"code","colab":{}},"cell_type":"code","source":["# TODO: Display an image along with the top 5 classes"],"execution_count":0,"outputs":[]}]}